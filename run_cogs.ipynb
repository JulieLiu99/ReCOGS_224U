{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import argparse\n",
    "import sys\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import logging\n",
    "import time\n",
    "from utils.cogs_utils import *\n",
    "import _pickle as cPickle\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, BertModel, BertConfig\n",
    "from model.encoder_decoder_hf import EncoderDecoderConfig, EncoderDecoderModel\n",
    "from model.encoder_decoder_lstm import EncoderDecoderLSTMModel\n",
    "import pandas as pd  \n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def find_partition_name(name, lf):\n",
    "    if lf == \"cogs\":\n",
    "        return name\n",
    "    else:\n",
    "        return name+f\"_{lf}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dcf329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COGSTrainer(object):\n",
    "    def __init__(\n",
    "        self, model,\n",
    "        is_master,\n",
    "        src_tokenizer, \n",
    "        tgt_tokenizer, \n",
    "        device,\n",
    "        logger,\n",
    "        lr=5e-5,\n",
    "        apex_enable=False,\n",
    "        n_gpu=1,\n",
    "        early_stopping=5,\n",
    "        do_statistic=False,\n",
    "        is_wandb=False,\n",
    "        model_name=\"\",\n",
    "        eval_acc=True,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "        self.is_master = is_master\n",
    "        self.logger = logger\n",
    "        self.is_wandb = is_wandb\n",
    "        self.model_name = model_name\n",
    "        self.eval_acc = eval_acc\n",
    "        \n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.n_gpu = n_gpu\n",
    "    \n",
    "        self.early_stopping = early_stopping\n",
    "    \n",
    "    def evaluate(\n",
    "        self, eval_dataloader,\n",
    "    ):\n",
    "        logging.info(\"Evaluating ...\")\n",
    "        loss_sum = 0.0\n",
    "        eval_step = 0\n",
    "        correct_count = 0\n",
    "        total_count = 0\n",
    "        self.model.eval()\n",
    "        for step, inputs in enumerate(eval_dataloader):\n",
    "            for k, v in inputs.items():\n",
    "                if v is not None and isinstance(v, torch.Tensor):\n",
    "                    inputs[k] = v.to(self.device)\n",
    "            input_ids = inputs[\"input_ids\"]\n",
    "            attention_mask = inputs[\"attention_mask\"]\n",
    "            labels = inputs[\"labels\"]\n",
    "            outputs = self.model(**inputs)\n",
    "            loss = outputs.loss.mean() if self.n_gpu > 1 else outputs.loss\n",
    "            loss_sum += loss.item()\n",
    "            eval_step += 1\n",
    "        self.model.train()\n",
    "        if total_count == 0:\n",
    "            return loss_sum / eval_step, 0\n",
    "        return loss_sum / eval_step, correct_count / total_count\n",
    "    \n",
    "    def train(\n",
    "        self, train_dataloader, eval_dataloader,\n",
    "        optimizer, scheduler, output_dir,\n",
    "        log_step, valid_steps, epochs, \n",
    "        gradient_accumulation_steps,\n",
    "        save_after_epoch\n",
    "    ):\n",
    "        self.model.train()\n",
    "        train_iterator = trange(\n",
    "            0, int(epochs), desc=\"Epoch\"\n",
    "        )\n",
    "        total_step = 0\n",
    "        total_log_step = 0\n",
    "        patient = 0\n",
    "        min_eval_loss = 100\n",
    "        for epoch in train_iterator:\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=f\"Epoch: {epoch}\", position=0, leave=True)\n",
    "            for step, inputs in enumerate(epoch_iterator):\n",
    "                if patient == self.early_stopping:\n",
    "                    logging.info(\"Early stopping the training ...\")\n",
    "                    break\n",
    "                for k, v in inputs.items():\n",
    "                    if v is not None and isinstance(v, torch.Tensor):\n",
    "                        inputs[k] = v.to(self.device)\n",
    "                outputs = self.model(**inputs)\n",
    "                loss = outputs.loss.mean() if self.n_gpu > 1 else outputs.loss\n",
    "                \n",
    "                if total_step % log_step == 0 and self.is_wandb:\n",
    "                    wandb.log(\n",
    "                        {\n",
    "                            \"train/loss\": loss.item(),\n",
    "                        },\n",
    "                        step=total_log_step\n",
    "                    )\n",
    "                    total_log_step += 1\n",
    "                loss_str = round(loss.item(), 2)\n",
    "                epoch_iterator.set_postfix({'loss': loss_str})\n",
    "                \n",
    "                if gradient_accumulation_steps > 1:\n",
    "                    loss = loss / gradient_accumulation_steps\n",
    "                \n",
    "                if total_step % gradient_accumulation_steps == 0:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    self.model.zero_grad()\n",
    "                    \n",
    "                total_step += 1\n",
    "                \n",
    "                if valid_steps != -1 and total_step % valid_steps == 0:\n",
    "                    eval_loss, eval_acc = self.evaluate(eval_dataloader)\n",
    "                    logging.info(f\"Eval Loss: {eval_loss}; Eval Acc: {eval_acc}\")\n",
    "                    if self.is_wandb:\n",
    "                        wandb.log(\n",
    "                            {\n",
    "                                \"eval/loss\": eval_loss.item(),\n",
    "                                \"eval/acc\": eval_acc,\n",
    "                            },\n",
    "                            step=total_step\n",
    "                        )\n",
    "                    if eval_loss < min_eval_loss:\n",
    "                        if self.is_master:\n",
    "                            if self.n_gpu > 1:\n",
    "                                self.model.module.save_pretrained(os.path.join(output_dir, 'model-best'))\n",
    "                            else:\n",
    "                                self.model.save_pretrained(os.path.join(output_dir, 'model-best'))\n",
    "                        min_eval_loss = eval_loss\n",
    "                        patient = 0\n",
    "                    else:\n",
    "                        patient += 1\n",
    "                        \n",
    "            if self.is_master:\n",
    "                if save_after_epoch is not None and epoch % save_after_epoch == 0:\n",
    "                    dir_name = f\"model-epoch-{epoch}\"\n",
    "                else:\n",
    "                    dir_name = \"model-last\"\n",
    "                if self.n_gpu > 1:\n",
    "                    self.model.module.save_pretrained(os.path.join(output_dir, dir_name))\n",
    "                else:\n",
    "                    self.model.save_pretrained(os.path.join(output_dir, dir_name))\n",
    "            if patient == self.early_stopping:\n",
    "                break\n",
    "        logging.info(\"Training is finished ...\") \n",
    "        if self.is_master:\n",
    "            if self.n_gpu > 1:\n",
    "                self.model.module.save_pretrained(os.path.join(output_dir, 'model-last'))\n",
    "            else:\n",
    "                self.model.save_pretrained(os.path.join(output_dir, 'model-last'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    is_notebook = False\n",
    "    try:\n",
    "        cmd = argparse.ArgumentParser('The testing components of')\n",
    "        cmd.add_argument('--gpu', default=-1, type=int, help='use id of gpu, -1 if cpu.')\n",
    "        cmd.add_argument('--train_batch_size', default=128, type=int, help='training batch size')\n",
    "        cmd.add_argument('--eval_batch_size', default=128, type=int, help='training batch size')\n",
    "        cmd.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
    "        cmd.add_argument('--data_path', required=True, type=str, help='path to the training corpus')\n",
    "        cmd.add_argument(\n",
    "            '--encoder_config_path', \n",
    "            type=str, help='path to the encoder config'\n",
    "        )\n",
    "        cmd.add_argument(\n",
    "            '--decoder_config_path', \n",
    "            type=str, help='path to the decoder config'\n",
    "        )\n",
    "        cmd.add_argument('--max_seq_len', default=512, type=int)\n",
    "        cmd.add_argument('--seed', default=42, type=int)\n",
    "        cmd.add_argument('--gradient_accumulation_steps', default=1, type=int)\n",
    "        cmd.add_argument('--output_dir', required=True, type=str, help='save dir')\n",
    "        cmd.add_argument('--local_rank', default=-1, type=int, help='multi gpu training')\n",
    "        cmd.add_argument('--epochs', default=10, type=int, help='training epochs')\n",
    "        cmd.add_argument('--model_path', type=str, required=False, default=None)\n",
    "        cmd.add_argument('--warm_up', type=float, default=0.1)\n",
    "        cmd.add_argument('--is_wandb', default=False, action='store_true')\n",
    "        cmd.add_argument('--spanformer', default=False, action='store_true')\n",
    "        cmd.add_argument('--log_step', default=10, type=int)\n",
    "        cmd.add_argument('--valid_steps', default=500, type=int)\n",
    "        cmd.add_argument('--early_stopping', default=5, type=int)\n",
    "        cmd.add_argument('--device', default=\"cuda\", type=str, help='')\n",
    "        cmd.add_argument('--do_train', default=False, action='store_true')\n",
    "        cmd.add_argument('--do_eval', default=False, action='store_true')\n",
    "        cmd.add_argument('--do_test', default=False, action='store_true')\n",
    "        cmd.add_argument('--do_gen', default=False, action='store_true')\n",
    "        cmd.add_argument('--least_to_most', default=False, action='store_true')\n",
    "        cmd.add_argument('--use_glove', default=False, action='store_true')\n",
    "        cmd.add_argument('--eval_acc', default=False, action='store_true')\n",
    "        cmd.add_argument('--use_iiem', default=False, action='store_true')\n",
    "        cmd.add_argument('--output_json', default=False, action='store_true')\n",
    "        cmd.add_argument('--save_after_epoch', type=int, default=None)\n",
    "        cmd.add_argument('--lf', default=\"cogs\", type=str, help='')\n",
    "        cmd.add_argument('--model_name', default=\"cogs\", type=str, help='')\n",
    "        \n",
    "        args = cmd.parse_args(sys.argv[1:])\n",
    "    except:\n",
    "        # LSTM settings best: {batch = 512, lr = 8e-4, epoch = 200}\n",
    "        # Transformer settings best: {batch = 128, lr = 1e-4, epoch = 200}\n",
    "        is_notebook = True\n",
    "        parser = argparse.ArgumentParser()\n",
    "        args = parser.parse_args([])\n",
    "        args.gpu = 1\n",
    "        args.train_batch_size = 128\n",
    "        args.eval_batch_size = 128\n",
    "        args.gradient_accumulation_steps = 1\n",
    "        args.lr = 1e-4\n",
    "        args.data_path = \"./cogs_participle_verb/\"\n",
    "        args.model_data_path = \"./model/\"\n",
    "        args.encoder_config_path = None\n",
    "        args.decoder_config_path = None\n",
    "        args.max_seq_len = 512\n",
    "        args.seed = 77\n",
    "        args.output_dir = \"./results_cogs_notebook/\"\n",
    "        args.epochs = 300\n",
    "        args.warm_up = 0.1\n",
    "        args.is_wandb = False\n",
    "        args.log_step = 10\n",
    "        # args.valid_steps = 500 # -1 not do training eval!\n",
    "        args.valid_steps = -1\n",
    "        args.early_stopping = None # large == never early stop!\n",
    "        args.device = \"cuda:0\"\n",
    "        args.spanformer = False\n",
    "        args.model_path = None\n",
    "        args.do_train = True\n",
    "        args.do_eval = False\n",
    "        args.do_test = True\n",
    "        args.do_gen = True\n",
    "        args.least_to_most = False\n",
    "        args.use_glove = False\n",
    "        args.eval_acc = False\n",
    "        args.save_after_epoch = None\n",
    "        args.use_iiem = False\n",
    "        args.output_json = False\n",
    "        args.model_name = \"ende_transformer\"\n",
    "        # args.lf = \"no_()\" # cogs, es, noexp\n",
    "        # args.model_path = \"./results_cogs_notebook/cogs_pipeline.model.ende_lstm.lf.cogs.glove.False.seed.42/model-last/\"\n",
    "        print(\"Using in a notebook env.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbdcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8363e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lf in [\n",
    "    \"cogs\",\n",
    "]:\n",
    "    for seed in [42]: # 42, 66, 77, 88, 99\n",
    "        set_seed(args.seed)\n",
    "        \n",
    "        args.lf = lf\n",
    "        args.seed = seed\n",
    "\n",
    "        model_name = args.model_name\n",
    "        run_name = f\"cogs_pipeline.model.{model_name}.lf.{args.lf}.glove.{args.use_glove}.seed.{args.seed}\"\n",
    "        if args.do_train == False:\n",
    "            args.model_path = f\"./results_cogs_notebook/{run_name}/model-last/\"\n",
    "        \n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.INFO)\n",
    "        device = torch.device(args.device)\n",
    "        \n",
    "        encoder_config_filename = \"encoder_config_lstm.json\" if model_name == \"ende_lstm\" else \"encoder_config.json\"\n",
    "        decoder_config_filename = \"decoder_config_lstm.json\" if model_name == \"ende_lstm\" else \"decoder_config.json\"\n",
    "        \n",
    "        \n",
    "        if \"participle_verb\" in args.data_path:\n",
    "            config_encoder = AutoConfig.from_pretrained(\n",
    "                os.path.join(args.data_path, encoder_config_filename)\n",
    "            )\n",
    "            config_decoder = AutoConfig.from_pretrained(\n",
    "                    os.path.join(args.data_path, decoder_config_filename) if args.decoder_config_path is None else \\\n",
    "                        args.decoder_config_path\n",
    "            )\n",
    "        else:\n",
    "            config_encoder = AutoConfig.from_pretrained(\n",
    "                os.path.join(args.model_data_path, encoder_config_filename)\n",
    "            )\n",
    "            config_decoder = AutoConfig.from_pretrained(\n",
    "                    os.path.join(args.model_data_path, decoder_config_filename) if args.decoder_config_path is None else \\\n",
    "                        args.decoder_config_path\n",
    "            )\n",
    "\n",
    "        if \"participle_verb\" in args.data_path:\n",
    "            src_tokenizer = WordLevelTokenizer(\n",
    "                os.path.join(args.data_path, \"src_vocab.txt\"), \n",
    "                config_encoder,\n",
    "                max_seq_len=args.max_seq_len\n",
    "            )\n",
    "            tgt_tokenizer = WordLevelTokenizer(\n",
    "                os.path.join(args.data_path, \"tgt_vocab.txt\"), \n",
    "                config_decoder,\n",
    "                max_seq_len=args.max_seq_len\n",
    "            )  \n",
    "        else:\n",
    "            src_tokenizer = WordLevelTokenizer(\n",
    "                os.path.join(args.model_data_path, \"src_vocab.txt\"), \n",
    "                config_encoder,\n",
    "                max_seq_len=args.max_seq_len\n",
    "            )\n",
    "            tgt_tokenizer = WordLevelTokenizer(\n",
    "                os.path.join(args.model_data_path, \"tgt_vocab.txt\"), \n",
    "                config_decoder,\n",
    "                max_seq_len=args.max_seq_len\n",
    "            )\n",
    "\n",
    "        if args.least_to_most:\n",
    "            logging.info(\"Preparing training set to be least to most order.\")\n",
    "        train_dataset = COGSDataset(\n",
    "            cogs_path=args.data_path, \n",
    "            src_tokenizer=src_tokenizer, \n",
    "            tgt_tokenizer=tgt_tokenizer, \n",
    "            partition=find_partition_name(\"train\", args.lf),\n",
    "            least_to_most=args.least_to_most\n",
    "        )\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset, batch_size=args.train_batch_size, \n",
    "            sampler=SequentialSampler(train_dataset),\n",
    "            collate_fn=train_dataset.collate_batch\n",
    "        )\n",
    "\n",
    "        eval_dataset = COGSDataset(\n",
    "            cogs_path=args.data_path, \n",
    "            src_tokenizer=src_tokenizer, \n",
    "            tgt_tokenizer=tgt_tokenizer, \n",
    "            partition=find_partition_name(\"dev\", args.lf),\n",
    "        )\n",
    "        eval_dataloader = DataLoader(\n",
    "            eval_dataset, batch_size=args.eval_batch_size, \n",
    "            sampler=SequentialSampler(eval_dataset),\n",
    "            collate_fn=train_dataset.collate_batch\n",
    "        )\n",
    "\n",
    "        test_dataset = COGSDataset(\n",
    "            cogs_path=args.data_path, \n",
    "            src_tokenizer=src_tokenizer, \n",
    "            tgt_tokenizer=tgt_tokenizer, \n",
    "            partition=find_partition_name(\"test\", args.lf),\n",
    "        )\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset, batch_size=args.eval_batch_size, \n",
    "            sampler=SequentialSampler(test_dataset),\n",
    "            collate_fn=train_dataset.collate_batch\n",
    "        )\n",
    "\n",
    "        gen_dataset = COGSDataset(\n",
    "            cogs_path=args.data_path, \n",
    "            src_tokenizer=src_tokenizer, \n",
    "            tgt_tokenizer=tgt_tokenizer, \n",
    "            partition=find_partition_name(\"gen\", args.lf),\n",
    "        )\n",
    "        gen_dataloader = DataLoader(\n",
    "            gen_dataset, batch_size=args.eval_batch_size, \n",
    "            sampler=SequentialSampler(gen_dataset),\n",
    "            collate_fn=train_dataset.collate_batch\n",
    "        )\n",
    "        \n",
    "        if model_name == \"ende_transformer\":\n",
    "            logging.info(\"Baselining the Transformer Encoder-Decoder Model\")\n",
    "            model_config = EncoderDecoderConfig.from_encoder_decoder_configs(\n",
    "                config_encoder, config_decoder\n",
    "            )\n",
    "            model_config.decoder_start_token_id = config_encoder.bos_token_id\n",
    "            model_config.pad_token_id = config_encoder.pad_token_id\n",
    "            model_config.eos_token_id = config_encoder.eos_token_id\n",
    "            model = EncoderDecoderModel(config=model_config)\n",
    "        elif model_name == \"ende_lstm\":\n",
    "            logging.info(\"Baselining the LSTM Encoder-Decoder Model\")\n",
    "            model_config = EncoderDecoderConfig.from_encoder_decoder_configs(\n",
    "                config_encoder, config_decoder\n",
    "            )\n",
    "            model_config.decoder_start_token_id = config_encoder.bos_token_id\n",
    "            model_config.pad_token_id = config_encoder.pad_token_id\n",
    "            model_config.eos_token_id = config_encoder.eos_token_id\n",
    "            model = EncoderDecoderLSTMModel(config=model_config)\n",
    "            \n",
    "        if args.model_path is not None and model_name == \"ende_transformer\":\n",
    "            logging.info(\"Loading pretrained model.\")\n",
    "            model = model.from_pretrained(args.model_path)\n",
    "        elif args.model_path is not None and model_name == \"ende_lstm\":\n",
    "            logging.info(\"Loading pretrained model.\")\n",
    "            raw_weights = torch.load(os.path.join(args.model_path, 'pytorch_model.bin'))\n",
    "            model.load_state_dict(raw_weights)\n",
    "            \n",
    "        \n",
    "\n",
    "        if \"cuda:\" not in args.device:\n",
    "            n_gpu = torch.cuda.device_count()\n",
    "            logging.info(f'__Number CUDA Devices: {n_gpu}')\n",
    "        else:\n",
    "            n_gpu = 1\n",
    "            logging.info(f'__Number CUDA Devices: {n_gpu}')\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        _ = model.to(device)\n",
    "\n",
    "        t_total = int(len(train_dataloader) * args.epochs)\n",
    "\n",
    "        warm_up_steps = args.warm_up * t_total\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), lr=args.lr\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warm_up_steps,\n",
    "                                                    num_training_steps=t_total)\n",
    "        is_master = True\n",
    "        apex_enable = False                                       \n",
    "        if not os.path.exists(args.output_dir) and is_master:\n",
    "            os.mkdir(args.output_dir)\n",
    "\n",
    "        os.environ[\"WANDB_PROJECT\"] = f\"COGS\"\n",
    "\n",
    "        output_dir = os.path.join(args.output_dir, run_name)\n",
    "        if args.is_wandb:\n",
    "            import wandb\n",
    "            run = wandb.init(\n",
    "                project=\"COGS-CKY-Transformer\", \n",
    "                entity=\"wuzhengx\",\n",
    "                name=run_name,\n",
    "            )\n",
    "            wandb.config.update(args)\n",
    "        if not os.path.exists(args.output_dir) and is_master:\n",
    "            os.mkdir(args.output_dir)\n",
    "\n",
    "        trainer = COGSTrainer(\n",
    "            model, device=device, \n",
    "            src_tokenizer=src_tokenizer, \n",
    "            tgt_tokenizer=tgt_tokenizer, \n",
    "            logger=logger,\n",
    "            is_master=is_master, \n",
    "            n_gpu=n_gpu,\n",
    "            is_wandb=args.is_wandb, \n",
    "            model_name=model_name,\n",
    "            eval_acc=args.eval_acc,\n",
    "            # early_stopping=args.early_stopping\n",
    "        )\n",
    "        num_params = count_parameters(model)\n",
    "        logging.info(f'Number of model params: {num_params}')\n",
    "\n",
    "        if args.do_train:\n",
    "            logging.info(f\"OUTPUT DIR: {output_dir}\")\n",
    "            trainer.train(\n",
    "                train_dataloader, eval_dataloader,\n",
    "                optimizer, scheduler, \n",
    "                log_step=args.log_step, valid_steps=args.valid_steps,\n",
    "                output_dir=output_dir, epochs=args.epochs, \n",
    "                gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "                save_after_epoch=args.save_after_epoch,\n",
    "            )\n",
    "        \n",
    "        if args.do_test and not args.use_iiem:\n",
    "            trainer.model.eval()\n",
    "            epoch_iterator = tqdm(test_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            for step, inputs in enumerate(epoch_iterator):\n",
    "                input_ids = inputs[\"input_ids\"].to(device)\n",
    "                attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "                labels = inputs[\"labels\"].to(device)\n",
    "                if model_name == \"ende_lstm\":\n",
    "                    outputs = trainer.model.generate(\n",
    "                        input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                    )\n",
    "                else:\n",
    "                    outputs = trainer.model.generate(\n",
    "                        input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        eos_token_id=model_config.eos_token_id,\n",
    "                        max_length=args.max_seq_len,\n",
    "                    )\n",
    "                decoded_preds = tgt_tokenizer.batch_decode(outputs)\n",
    "                decoded_labels = tgt_tokenizer.batch_decode(labels)\n",
    "\n",
    "                for i in range(len(decoded_preds)):\n",
    "                    if args.use_span_match:\n",
    "                        if set(decoded_preds[i].split(\" ; \")) == set(decoded_labels[i].split(\" ; \")):\n",
    "                            correct_count += 1\n",
    "                        else:\n",
    "                            print(decoded_preds[i])\n",
    "                            print(decoded_labels[i])\n",
    "                    else:\n",
    "                        if decoded_preds[i] == decoded_labels[i]:\n",
    "                            correct_count += 1\n",
    "                        else:\n",
    "                            print(decoded_preds[i])\n",
    "                            print(decoded_labels[i])\n",
    "                    total_count += 1\n",
    "                current_acc = round(correct_count/total_count, 2)\n",
    "                epoch_iterator.set_postfix({'acc': current_acc})\n",
    "            test_acc = current_acc\n",
    "\n",
    "        if args.do_gen and not args.use_iiem:\n",
    "            per_cat_eval = {}\n",
    "            for cat in set(gen_dataset.eval_cat):\n",
    "                per_cat_eval[cat] = [0, 0] # correct, total\n",
    "            trainer.model.eval()\n",
    "            epoch_iterator = tqdm(gen_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            for step, inputs in enumerate(epoch_iterator):\n",
    "                input_ids = inputs[\"input_ids\"].to(device)\n",
    "                attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "                labels = inputs[\"labels\"].to(device)\n",
    "                if model_name == \"ende_lstm\":\n",
    "                    outputs = trainer.model.generate(\n",
    "                        input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                    )\n",
    "                else:\n",
    "                    outputs = trainer.model.generate(\n",
    "                        input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        eos_token_id=model_config.eos_token_id,\n",
    "                        max_length=args.max_seq_len,\n",
    "                    )\n",
    "                decoded_preds = tgt_tokenizer.batch_decode(outputs)\n",
    "                decoded_labels = tgt_tokenizer.batch_decode(labels)\n",
    "\n",
    "                input_labels = src_tokenizer.batch_decode(input_ids)\n",
    "                for i in range(len(decoded_preds)):\n",
    "                    cat = gen_dataset.eval_cat[total_count]\n",
    "                    if args.use_span_match:\n",
    "                        if set(decoded_preds[i].split(\" ; \")) == set(decoded_labels[i].split(\" ; \")):\n",
    "                            correct_count += 1\n",
    "                            per_cat_eval[cat][0] += 1\n",
    "                        else:\n",
    "                            if cat == \"obj_pp_to_subj_pp\":\n",
    "                                pass\n",
    "        #                         print(\"input: \", input_labels[i])\n",
    "        #                         print(\"pred: \", decoded_preds[i])\n",
    "        #                         print(\"actual: \", decoded_labels[i])\n",
    "        #                         print(\"cat: \", cat)\n",
    "        #                         print()\n",
    "                    else:\n",
    "                        if decoded_preds[i] == decoded_labels[i]:\n",
    "                            correct_count += 1\n",
    "                            per_cat_eval[cat][0] += 1\n",
    "                        else:\n",
    "                            if cat == \"prim_to_obj_proper\":\n",
    "                                pass\n",
    "        #                             print(\"input: \", input_labels[i])\n",
    "        #                             print(\"pred: \", decoded_preds[i])\n",
    "        #                             print(\"actual: \", decoded_labels[i])\n",
    "        #                             print(\"cat: \", cat)\n",
    "        #                             print()\n",
    "                    total_count += 1\n",
    "                    per_cat_eval[cat][1] += 1\n",
    "                current_acc = correct_count/total_count\n",
    "                epoch_iterator.set_postfix({'acc': current_acc})\n",
    "\n",
    "            struct_pp_acc = 0\n",
    "            struct_cp_acc = 0\n",
    "            struct_obj_subj_acc = 0\n",
    "\n",
    "            lex_acc = 0\n",
    "            lex_count = 0\n",
    "            for k, v in per_cat_eval.items():\n",
    "                if k  == \"pp_recursion\":\n",
    "                    struct_pp_acc = 100 * v[0]/v[1]\n",
    "                elif k  == \"cp_recursion\":\n",
    "                    struct_cp_acc = 100 * v[0]/v[1]\n",
    "                elif k  == \"obj_pp_to_subj_pp\":\n",
    "                    struct_obj_subj_acc = 100 * v[0]/v[1]\n",
    "                elif k  == \"subj_to_obj_proper\":\n",
    "                    subj_to_obj_proper_acc = 100 * v[0]/v[1]\n",
    "                elif k  == \"prim_to_obj_proper\":\n",
    "                    prim_to_obj_proper_acc = 100 * v[0]/v[1]\n",
    "                elif k  == \"prim_to_subj_proper\": \n",
    "                    prim_to_subj_proper_acc = 100 * v[0]/v[1]\n",
    "                else:\n",
    "                    lex_acc += v[0]\n",
    "                    lex_count += v[1]\n",
    "            lex_acc /= lex_count\n",
    "            lex_acc *= 100\n",
    "            current_acc *= 100\n",
    "\n",
    "            print(f\"obj_pp_to_subj_pp: {struct_obj_subj_acc}\")\n",
    "            print(f\"cp_recursion: {struct_cp_acc}\")\n",
    "            print(f\"pp_recursion: {struct_pp_acc}\")\n",
    "            print(f\"subj_to_obj_proper: {subj_to_obj_proper_acc}\")\n",
    "            print(f\"prim_to_obj_proper: {prim_to_obj_proper_acc}\")\n",
    "            print(f\"prim_to_subj_proper: {prim_to_subj_proper_acc}\")\n",
    "            print(f\"LEX: {lex_acc}\")\n",
    "            print(f\"OVERALL: {current_acc}\")\n",
    "\n",
    "            results[(seed, lf)] = {\n",
    "                \"obj_pp_to_subj_pp\" : struct_obj_subj_acc,\n",
    "                \"cp_recursion\" : struct_cp_acc,\n",
    "                \"pp_recursion\" : struct_pp_acc,\n",
    "                \"subj_to_obj_proper\" : subj_to_obj_proper_acc,\n",
    "                \"prim_to_obj_proper\" : prim_to_obj_proper_acc,\n",
    "                \"prim_to_subj_proper\" : prim_to_subj_proper_acc,\n",
    "                \"lex_acc\" : lex_acc,\n",
    "                \"overall_acc\" : current_acc,\n",
    "                \"test_acc\" : test_acc\n",
    "            }\n",
    "\n",
    "        if args.do_test and args.use_iiem:\n",
    "            trainer.model.eval()\n",
    "            epoch_iterator = tqdm(test_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            for step, inputs in enumerate(epoch_iterator):\n",
    "                input_ids = inputs[\"input_ids\"].to(device)\n",
    "                attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "                labels = inputs[\"labels\"].to(device)\n",
    "                outputs = trainer.model.generate(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "            #         eos_token_id=model_config.eos_token_id,\n",
    "            #         max_length=512,\n",
    "                )\n",
    "                decoded_preds = tgt_tokenizer.batch_decode(outputs)\n",
    "                decoded_labels = tgt_tokenizer.batch_decode(labels)\n",
    "\n",
    "                for i in range(len(decoded_preds)):\n",
    "\n",
    "                    index_mapping = {}\n",
    "                    current_idx = 0\n",
    "                    for t in decoded_labels[i].split():\n",
    "                        if t.isnumeric():\n",
    "                            if int(t) not in index_mapping:\n",
    "                                index_mapping[int(t)] = current_idx\n",
    "                                current_idx += 1\n",
    "                    decoded_labels_ii = []\n",
    "                    for t in decoded_labels[i].split():\n",
    "                        if t.isnumeric():\n",
    "                            decoded_labels_ii += [str(index_mapping[int(t)])]\n",
    "                        else:\n",
    "                            decoded_labels_ii += [t]\n",
    "\n",
    "                    index_mapping = {}\n",
    "                    current_idx = 0\n",
    "                    for t in decoded_preds[i].split():\n",
    "                        if t.isnumeric():\n",
    "                            if int(t) not in index_mapping:\n",
    "                                index_mapping[int(t)] = current_idx\n",
    "                                current_idx += 1\n",
    "                    decoded_preds_ii = []\n",
    "                    for t in decoded_preds[i].split():\n",
    "                        if t.isnumeric():\n",
    "                            decoded_preds_ii += [str(index_mapping[int(t)])]\n",
    "                        else:\n",
    "                            decoded_preds_ii += [t]\n",
    "\n",
    "\n",
    "                    decoded_labels_ii_str = \" \".join(decoded_labels_ii)\n",
    "                    decoded_preds_ii_str = \" \".join(decoded_preds_ii)\n",
    "\n",
    "                    if decoded_preds_ii_str == decoded_labels_ii_str:\n",
    "                        correct_count += 1\n",
    "                    else:\n",
    "                        print(decoded_labels_ii_str)\n",
    "                        print(decoded_preds_ii_str)\n",
    "\n",
    "                    total_count += 1\n",
    "                current_acc = round(correct_count/total_count, 2)\n",
    "                epoch_iterator.set_postfix({'acc': current_acc})\n",
    "\n",
    "        if args.do_gen and args.use_iiem:\n",
    "            per_cat_eval = {}\n",
    "            for cat in set(gen_dataset.eval_cat):\n",
    "                per_cat_eval[cat] = [0, 0] # correct, total\n",
    "            trainer.model.eval()\n",
    "            epoch_iterator = tqdm(gen_dataloader, desc=\"Iteration\", position=0, leave=True)\n",
    "            total_count = 0\n",
    "            correct_count = 0\n",
    "            for step, inputs in enumerate(epoch_iterator):\n",
    "                input_ids = inputs[\"input_ids\"].to(device)\n",
    "                attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "                labels = inputs[\"labels\"].to(device)\n",
    "                outputs = trainer.model.generate(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "            #         eos_token_id=model_config.eos_token_id,\n",
    "            #         max_length=args.max_seq_len\n",
    "                )\n",
    "                decoded_preds = tgt_tokenizer.batch_decode(outputs)\n",
    "                decoded_labels = tgt_tokenizer.batch_decode(labels)\n",
    "\n",
    "                input_labels = src_tokenizer.batch_decode(input_ids)\n",
    "                for i in range(len(decoded_preds)):\n",
    "\n",
    "                    index_mapping = {}\n",
    "                    current_idx = 0\n",
    "                    for t in decoded_labels[i].split():\n",
    "                        if t.isnumeric():\n",
    "                            if int(t) not in index_mapping:\n",
    "                                index_mapping[int(t)] = current_idx\n",
    "                                current_idx += 1\n",
    "                    decoded_labels_ii = []\n",
    "                    for t in decoded_labels[i].split():\n",
    "                        if t.isnumeric():\n",
    "                            decoded_labels_ii += [str(index_mapping[int(t)])]\n",
    "                        else:\n",
    "                            decoded_labels_ii += [t]\n",
    "\n",
    "                    index_mapping = {}\n",
    "                    current_idx = 0\n",
    "                    for t in decoded_preds[i].split():\n",
    "                        if t.isnumeric():\n",
    "                            if int(t) not in index_mapping:\n",
    "                                index_mapping[int(t)] = current_idx\n",
    "                                current_idx += 1\n",
    "                    decoded_preds_ii = []\n",
    "                    for t in decoded_preds[i].split():\n",
    "                        if t.isnumeric():\n",
    "                            decoded_preds_ii += [str(index_mapping[int(t)])]\n",
    "                        else:\n",
    "                            decoded_preds_ii += [t]\n",
    "\n",
    "\n",
    "                    decoded_labels_ii_str = \" \".join(decoded_labels_ii)\n",
    "                    decoded_preds_ii_str = \" \".join(decoded_preds_ii)\n",
    "\n",
    "                    cat = gen_dataset.eval_cat[total_count]\n",
    "                    if decoded_preds_ii_str == decoded_labels_ii_str:\n",
    "                        correct_count += 1\n",
    "                        per_cat_eval[cat][0] += 1\n",
    "                        if cat == \"obj_pp_to_subj_pp\":\n",
    "                            pass\n",
    "                    else:\n",
    "                        if cat == \"obj_pp_to_subj_pp\":\n",
    "                            # pass\n",
    "                            print(\"input: \", input_labels[i])\n",
    "                            print(\"pred: \", decoded_preds_ii_str)\n",
    "                            print(\"actual: \", decoded_labels_ii_str)\n",
    "                            print(\"cat: \", cat)\n",
    "                            print()\n",
    "                    total_count += 1\n",
    "                    per_cat_eval[cat][1] += 1\n",
    "                current_acc = correct_count/total_count\n",
    "                epoch_iterator.set_postfix({'acc': current_acc})\n",
    "\n",
    "            struct_pp_acc = 0\n",
    "            struct_cp_acc = 0\n",
    "            struct_obj_subj_acc = 0\n",
    "\n",
    "            lex_acc = 0\n",
    "            lex_count = 0\n",
    "            for k, v in per_cat_eval.items():\n",
    "                if k  == \"pp_recursion\":\n",
    "                    struct_pp_acc = 100 * v[0]/v[1]\n",
    "                elif k  == \"cp_recursion\":\n",
    "                    struct_cp_acc = 100 * v[0]/v[1]\n",
    "                elif k  == \"obj_pp_to_subj_pp\":\n",
    "                    struct_obj_subj_acc = 100 * v[0]/v[1]\n",
    "                elif k  == \"subj_to_obj_proper\":\n",
    "                    subj_to_obj_proper_acc = 100 * v[0]/v[1]\n",
    "                elif k  == \"prim_to_obj_proper\":\n",
    "                    prim_to_obj_proper_acc = 100 * v[0]/v[1]\n",
    "                elif k  == \"prim_to_subj_proper\":\n",
    "                    prim_to_subj_proper_acc = 100 * v[0]/v[1]\n",
    "                else:\n",
    "                    lex_acc += v[0]\n",
    "                    lex_count += v[1]\n",
    "            lex_acc /= lex_count\n",
    "            lex_acc *= 100\n",
    "            current_acc *= 100\n",
    "\n",
    "            print(f\"obj_pp_to_subj_pp: {struct_obj_subj_acc}\")\n",
    "            print(f\"cp_recursion: {struct_cp_acc}\")\n",
    "            print(f\"pp_recursion: {struct_pp_acc}\")\n",
    "            print(f\"subj_to_obj_proper: {subj_to_obj_proper_acc}\")\n",
    "            print(f\"prim_to_obj_proper: {prim_to_obj_proper_acc}\")\n",
    "            print(f\"prim_to_subj_proper: {prim_to_subj_proper_acc}\")\n",
    "            print(f\"LEX: {lex_acc}\")\n",
    "            print(f\"OVERALL: {current_acc}\")\n",
    "\n",
    "            results[(seed, lf)] = {\n",
    "                \"obj_pp_to_subj_pp\" : struct_obj_subj_acc,\n",
    "                \"cp_recursion\" : struct_cp_acc,\n",
    "                \"pp_recursion\" : struct_pp_acc,\n",
    "                \"subj_to_obj_proper\" : subj_to_obj_proper_acc,\n",
    "                \"prim_to_obj_proper\" : prim_to_obj_proper_acc,\n",
    "                \"prim_to_subj_proper\" : prim_to_subj_proper_acc,\n",
    "                \"lex_acc\" : lex_acc,\n",
    "                \"overall_acc\" : current_acc,\n",
    "                \"test_acc\" : test_acc\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5220de8e",
   "metadata": {},
   "source": [
    "### Eval without absolute indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.output_json:\n",
    "    import json\n",
    "    json_object = json.dumps(results, indent=4)\n",
    "    data_filename = args.data_path.strip(\"./\")\n",
    "    with open(f\"{data_filename}.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d5c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
